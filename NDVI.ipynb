{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDVI Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "import sentinelsat\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import os\n",
    "import lithops\n",
    "import random\n",
    "import rasterio\n",
    "import re\n",
    "import tempfile\n",
    "import zipfile\n",
    "import subprocess\n",
    "import glob\n",
    "import json\n",
    "from rio_cogeo import cogeo\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import date\n",
    "from fiona.io import ZipMemoryFile\n",
    "from matplotlib import pyplot as plt\n",
    "from rasterio.io import MemoryFile\n",
    "from zipfile import ZipFile\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles\n",
    "from lithops.storage import Storage\n",
    "\n",
    "from utils import notebook as notebook_utils\n",
    "from io_utils.ndvi import get_ndvi_params, ndvi_calculation, ndvi_tile_sentinel, get_subset_raster, lonlat_to_utm, get_poly_within\n",
    "from io_utils.plot import tiff_overview, plot_map\n",
    "\n",
    "os.environ['CURL_CA_BUNDLE'] = '/etc/ssl/certs/ca-certificates.crt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the environmental variables *SENTINEL_USERNAME* and *SENTINEL_PASSWORD* to match your Sentinel-2 credentials. You can register and access data for free at https://sentinel.esa.int/web/sentinel/sentinel-data-access/registration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTINEL_USERNAME = ...\n",
    "SENTINEL_PASSWORD = ...\n",
    "STORAGE_BUCKET = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_storage = Storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the date interval in which tiles will be processed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3da407e33c843e0b73e7cdd5eb7980e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DatePicker(value=datetime.date(2019, 11, 1), description='From day')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44584b1dc9964b759e105ab7f7d4851e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DatePicker(value=datetime.date(2019, 11, 30), description='To day')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from_day, to_day = notebook_utils.pick_date_range()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the tile's cloud percentage threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a8ae39875e455e8be5d59a4c1702f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=15, continuous_update=False, description='Porcentaje de nubosidad')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "percentage = notebook_utils.pick_percentage_slider()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the area which delimites the tiles you want to process (left click to mark a point in the map, right click to erase current selection):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f2ff7dff854618b254f61c8fb1510c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(basemap={'url': 'http://{s}.tile.openstreetmap.fr/hot/{z}/{x}/{y}.png', 'max_zoom': 19, 'attribution': '&câ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_region = notebook_utils.MapRegion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Sentinel-2 metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locations = map_region.get_region()\n",
    "# TODO hardcoded for dev purposes\n",
    "locations = [[-1.32110595703125, 37.57329031970199],\n",
    " [-2.0681762695312504, 37.684227882053044],\n",
    " [-1.636962890625, 38.24289903439589],\n",
    " [-0.7745361328125, 38.12199840979802],\n",
    " [-1.32110595703125, 37.57329031970199]]\n",
    "locations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the selected parameters, get the identifiers of the selected tiles from Sentinel-2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_json_area = {\"features\": [{\"geometry\": {\"coordinates\": [locations], \"type\": \"Polygon\"}, \"properties\": {}, \"type\": \"Feature\"}], \"type\": \"FeatureCollection\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_api = sentinelsat.SentinelAPI(user=SENTINEL_USERNAME,\n",
    "                                       password=SENTINEL_PASSWORD)\n",
    "footprint = sentinelsat.geojson_to_wkt(geo_json_area)\n",
    "products = sentinel_api.query(footprint,\n",
    "                              date=(from_day.value, to_day.value),\n",
    "                              platformname='Sentinel-2',\n",
    "                              producttype=('S2MS2Ap', 'S2MSI1C'),\n",
    "                              cloudcoverpercentage=(0, percentage.value))\n",
    "geojson_products = sentinel_api.to_geojson(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For debug purposes, we will compute one tile. Skip this cell to compute all tiles.\n",
    "geojson_products = [geojson_products[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of tiles: {}'.format(len(geojson_products)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Athmospheric correction using Serverful Lithops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will download tile images from Sentinel2 using the previously selected configuration and apply athmospheric correction.\n",
    "\n",
    "This process is not parallelizable and lasts for over 20 minutes, so it is not suited for serverless functions. We will use Lithops Standalone instead, which uses serverful instances that haven't time limits.\n",
    "\n",
    "The runtime used packs Sentinel2 software and IBM Cloud Functions Python3.7 handler in a Dockerfile located in `sentinel2_runtime/Dockerfile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jp2_to_cog(band_src_path):\n",
    "    \"\"\"\n",
    "    Transform a sentinel2 band (.jp2) to GeoTiff (.tif)\n",
    "    \"\"\"\n",
    "    config = dict(NUM_THREADS=100, GDAL_TIFF_OVR_BLOCKSIZE=128)\n",
    "\n",
    "    output_profile = {\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"interleave\": \"pixel\",\n",
    "        \"tiled\": True,\n",
    "        \"blockxsize\": 256,\n",
    "        \"blockysize\": 256,\n",
    "        \"compress\": \"DEFLATE\",\n",
    "    }\n",
    "\n",
    "    cog_path = f\"{band_src_path[band_src_path.rfind('/')+1:band_src_path.rfind('.')]}.tif\"\n",
    "    cogeo.cog_translate(\n",
    "        band_src_path,\n",
    "        cog_path,\n",
    "        output_profile,\n",
    "        nodata=0,\n",
    "        in_memory=False,\n",
    "        config=config,\n",
    "        quiet=True,\n",
    "    )\n",
    "\n",
    "    return cog_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_atmospheric_correction(product_geojson, storage):\n",
    "    product = product_geojson['properties']\n",
    "    tile = product['filename'][39:44]\n",
    "    date = product['filename'][11:19]\n",
    "\n",
    "    # Check if tile is already processed stored in COS, return if it is\n",
    "    #keys = storage.list_keys(bucket=STORAGE_BUCKET)\n",
    "    keys = []\n",
    "    pattern = r\".*\" + re.escape(date) + r\".*\" + re.escape(tile) + r\".*\\.geojson\"\n",
    "    filtered = [file for file in keys if re.search(pattern, file)]\n",
    "    if filtered:\n",
    "        print('Tile already in COS: {}'.format(filtered))\n",
    "        remote_geotiff = filtered.pop()\n",
    "        return remote_geotiff\n",
    "\n",
    "    # Download Sentinel-2 tile\n",
    "    sentinel_api = sentinelsat.SentinelAPI(user=os.environ[\"SENTINEL_USERNAME\"],\n",
    "                                           password=os.environ[\"SENTINEL_PASSWORD\"])\n",
    "\n",
    "    sentinel_product_dir = product['filename']\n",
    "    tmpdir = tempfile.gettempdir()\n",
    "    d_meta = sentinel_api.download(product['uuid'], directory_path=tmpdir)\n",
    "    \n",
    "    # Extract and remove zip file\n",
    "    zip_ref = zipfile.ZipFile(d_meta['path'])\n",
    "    zip_ref.extractall(tmpdir)\n",
    "    zip_ref.close()\n",
    "    #os.remove(d_meta['path'])\n",
    "\n",
    "    # Atmospheric correction\n",
    "    sentinel_product_dir = os.path.join(tmpdir, product['filename'])\n",
    "    corrected_images = glob.glob(f\"*2A_{date}*_T{tile}_*.SAFE/GRANULE/*/IMG_DATA/R10m/*B0[48]*.jp2\")\n",
    "    atmospheric_corrected = corrected_images[0] if len(corrected_images) > 0 else None\n",
    "\n",
    "    if not atmospheric_corrected:\n",
    "        print(f'Doing the atmospheric correction for {sentinel_product_dir}')\n",
    "        try:\n",
    "            cmd = ['L2A_Process --resolution 10 {}'.format(sentinel_product_dir)]\n",
    "            val = subprocess.check_output(cmd, stderr=subprocess.STDOUT, shell=True, universal_newlines=True)\n",
    "            corrected_images = glob.glob(f\"*2A_{date}*_T{tile}_*.SAFE/GRANULE/*/IMG_DATA/R10m/*B0[48]*.jp2\")\n",
    "            print(f'Atmospheric correction finished {val}')\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(e.returncode)\n",
    "            print(e.output)\n",
    "            print(e.stderr)\n",
    "            raise(e)\n",
    "\n",
    "\n",
    "    # Translate bands in .jp2 to GeoTiff format\n",
    "    band_files = []\n",
    "    band4 = glob.glob(os.path.join(tmpdir, '*L2A_{}*_T{}*.SAFE/GRANULE/*/IMG_DATA/R10m/*B04*'.format(date, tile))).pop()\n",
    "    band8 = glob.glob(os.path.join(tmpdir, '*L2A_{}*_T{}*.SAFE/GRANULE/*/IMG_DATA/R10m/*B08*'.format(date, tile))).pop()\n",
    "\n",
    "    if band4 is not None and band8 is not None:\n",
    "        band4_tiff_file = f\"{band4[band4.rfind('/')+1:band4.rfind('.')]}.tif\"\n",
    "        band8_tiff_file = f\"{band8[band8.rfind('/') + 1:band8.rfind('.')]}.tif\"\n",
    "        jp2_to_cog(band4)\n",
    "        jp2_to_cog(band8)\n",
    "        band_files.append(band4_tiff_file)\n",
    "        band_files.append(band8_tiff_file)\n",
    "    \n",
    "    print(band_files)\n",
    "\n",
    "    # Merge both bands into a single geotiff\n",
    "    combined_geotiff_key = band_files[0][0:22] + '_COMBINED.tif'\n",
    "    with rasterio.open(band_files[0]) as src:\n",
    "        profile = src.profile\n",
    "        profile.update(count=len(band_files))\n",
    "\n",
    "    with rasterio.open(combined_geotiff_key, 'w', **profile) as dst:\n",
    "        for i, band_file in enumerate(band_files):\n",
    "            with rasterio.open(band_file) as src:\n",
    "                dst.write(src.read(1), i + 1)\n",
    "\n",
    "    # Upload generated files to Cloud Storage\n",
    "    with open(combined_geotiff_key, 'rb') as combined_geotiff_f:\n",
    "        storage.put_object(bucket=STORAGE_BUCKET, key=combined_geotiff_key, body=combined_geotiff_f)\n",
    "    product_meta_key = combined_geotiff_key + '.meta.json'\n",
    "    storage.put_object(bucket=STORAGE_BUCKET, key=product_meta_key, body=json.dumps(product))\n",
    "\n",
    "    return combined_geotiff_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lithops_standalone = lithops.StandaloneExecutor(runtime='aitorarjona/lithops_ndvi_sen2cor:1.0', workers=1, log_level='DEBUG')\n",
    "extra_env = {'SENTINEL_USERNAME': SENTINEL_USERNAME,\n",
    "             'SENTINEL_PASSWORD': SENTINEL_PASSWORD}\n",
    "lithops_standalone.map(perform_atmospheric_correction, geojson_products, extra_env=extra_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_keys = lithops_standalone.get_result()\n",
    "print(combined_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NDVI Computation using Serverless Lithops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will calculate NDVI index of tiles tha thave been downloaded and pre-processed before.\n",
    "\n",
    "This process can be executed in parallel (for every tile) and in serverless functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithops_serverless = lithops.ServerlessExecutor(runtime='cloudbuttonans/geospatial-runtime:3.7-v4', runtime_memory=2048, log_level='DEBUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "combined_keys = ['T30SWG_20191127T105309_COMBINED.tif']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndvi(combined_key, storage):\n",
    "    tmpdir = tempfile.gettempdir()\n",
    "    dat = storage.get_object(bucket=STORAGE_BUCKET, key=combined_key, stream=True)\n",
    "    out = os.path.join(tmpdir, 'out.tif')\n",
    "\n",
    "    with rasterio.open(dat) as src:\n",
    "        profile = src.profile\n",
    "        profile.update(dtype='float32')\n",
    "        profile.update(count=1)\n",
    "        with rasterio.open(out, 'w', **profile) as dst:\n",
    "            for _, window in src.block_windows(1):\n",
    "                red = src.read(1, window=window).astype('float32')\n",
    "                nir = src.read(2, window=window).astype('float32')\n",
    "                ndvi = (np.where((nir + red) == 0., 0,\n",
    "                                 (nir - red) / (nir + red))).astype('float32')\n",
    "                dst.write(ndvi, 1, window=window)\n",
    "\n",
    "    prefix = combined_key.rsplit('_', 1)[0]\n",
    "    output_key = prefix + '_NDVI.tif'\n",
    "    with open(out, 'rb') as output_f:\n",
    "        storage.put_object(bucket=STORAGE_BUCKET, key=output_key, body=output_f)\n",
    "\n",
    "    return output_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithops_serverless.map(ndvi, combined_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_keys = lithops_serverless.get_result()\n",
    "ndvi_keys = ['T30SWG_20191127T105309_NDVI.tif']  # DEBUG\n",
    "ndvi_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_select = notebook_utils.pick_tile(ndvi_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = cloud_storage.get_object(bucket=STORAGE_BUCKET, key='T30SWG_20191127T105309_NDVI.tif', stream=True)\n",
    "fig, axs = plt.subplots(figsize=(20,15))\n",
    "with rasterio.open(obj) as src:\n",
    "    ij, window = random.choice(list(src.block_windows()))\n",
    "    arr = src.read(1, window=window)\n",
    "    plt.imshow(arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "geospatial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
